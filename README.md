# Real-Time Facial Emotion Recognition using CNN

This project implements a Convolutional Neural Network (CNN) using TensorFlow/Keras to recognize facial emotions (e.g., happy, sad, angry) from a live webcam feed. It uses OpenCV for image handling and MediaPipe for robust face detection.

## Features

* **Data Preparation:** Processes image datasets, detects faces using MediaPipe, converts to grayscale, resizes, and saves them as NumPy arrays (`.npy`).
* **CNN Model Training:** Builds and trains a CNN model on the prepared dataset with data augmentation, class weighting, and callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau). Saves the best model (`.keras`).
* **Real-Time Recognition:** Uses the trained model to predict emotions from faces detected in a live webcam stream via OpenCV. Displays the detected emotion and FPS.
* **Evaluation:** Generates a classification report and confusion matrix after training. Saves plots for training history and the confusion matrix.

## File Structure

```txt
├── Terminal output/              # Directory for terminal output
│   ├── prepareData.txt/
│   ├── testModel.txt/
│   └── trainModel.txt/
├── .gitignore         # Specifies intentionally untracked files that Git should ignore
├── prepareData.py     # Script to process the image dataset
├── trainModel.py      # Script to build and train the CNN model
├── testModel.py       # Script for real-time emotion recognition via webcam
├── utils.py           # Utility functions (e.g., face detection using MediaPipe)
├── requirements.txt   # Lists Python dependencies
├── README.md          # This file
├── data/              # Directory for dataset (Needs to be created by user)
│   ├── train/
│   │   ├── happy/
│   │   ├── sad/   
│   │   └── ... (other emotion folders)
│   └── test/
│       ├── happy/
│       ├── sad/
│       └── ... (other emotion folders)
├── .venv/             
# Python virtual environment directory (ignored by git)
# Needs to be created by user
```
 
## Generated Files (ignored by git) 

```txt
├── X_train.npy
├── y_train.npy
├── X_test.npy
├── y_test.npy
├── emotion_labels.npy
├── emotion_cnn_model_v2.keras
├── confusion_matrix.png
└── training_history.png
```

## Technologies Used

* Python 3.x
* TensorFlow / Keras
* OpenCV (`opencv-python`)
* MediaPipe
* NumPy
* Scikit-learn
* Matplotlib
* Seaborn
* tqdm

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd <repository-directory>
    ```

2.  **Create and activate a virtual environment:** (Recommended)
    ```bash
    # On windows: Use inbuilt virtual enviornment maker of VS Code. 
    # It will create the virtual environment using the name .venv.
    
    # On macOS/Linux:
    python -m venv .venv

    # Activate it
    # On Windows:
    source ".venv/Scripts/activate"
    # On macOS/Linux:
    source .venv/bin/activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: TensorFlow installation might vary depending on whether you need GPU support. Refer to the official TensorFlow installation guide if needed.)*

4.  **Prepare your dataset:**
    * Create the `data/train` and `data/test` directories.
    * Inside both `train` and `test`, create subdirectories for each emotion category (e.g., `happy`, `sad`, `neutral`, `angry`, etc.). The names of these folders will be used as the emotion labels.
    * Place the corresponding images into these emotion subfolders. The project expects image files (e.g., `.jpg`, `.png`).

## Usage

1.  **Prepare Data:**
    * Run the data preparation script. This will process images from the `data/` directory, detect faces, and save the processed data as `.npy` files in the project's root directory.
    ```bash
    python prepareData.py
    ```
    *(This might take some time depending on the dataset size.)*

2.  **Train the Model:**
    * Run the training script. This will load the `.npy` files, build the CNN, train it, and save the best model as `emotion_cnn_model_v2.keras`. It will also save `confusion_matrix.png` and `training_history.png`.
    ```bash
    python trainModel.py
    ```

3.  **Test in Real-Time:**
    * Ensure you have a webcam connected.
    * Run the testing script. It will load the saved model (`.keras`) and labels (`.npy`), open your webcam, detect faces, predict emotions, and display the results.
    ```bash
    python testModel.py
    ```
    * Press 'q' to quit the webcam feed.

## Notes

* The generated `.npy` data files, `.keras` model file, and `.png` plots are included in the `.gitignore` file as they can be large and are generated by the scripts.
* The performance depends heavily on the quality and quantity of the training data and the model architecture/hyperparameters.
* Ensure the `MODEL_SAVE_PATH` and `LABEL_MAP_PATH` constants in `trainModel.py` and `testModel.py` match the actual filenames.